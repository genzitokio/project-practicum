{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кейс 1: Предсказание оттока клиентов кредитных карт\n",
    "\n",
    "**Цель**: Построить модель бинарной классификации для предсказания оттока клиентов банка.\n",
    "\n",
    "**Датасет**: [Credit Card Customers](https://www.kaggle.com/datasets/whenamancodes/credit-card-customers-prediction)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, precision_score, f1_score, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Настройки отображения\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Загрузка и первичный осмотр данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/BankChurners.csv')\n",
    "\n",
    "print('Размер датасета:', df.shape)\n",
    "print(f'\\nСтрок: {df.shape[0]}, Столбцов: {df.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Первые строки\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Типы данных\n",
    "print('Типы данных:')\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Базовая статистика\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Информация о датасете\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Проверка пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df.isnull().sum()\n",
    "missing_pct = (df.isnull().sum() / len(df) * 100).round(2)\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Пропуски': missing,\n",
    "    'Процент': missing_pct\n",
    "})\n",
    "\n",
    "print('Пропущенные значения:')\n",
    "print(missing_df[missing_df['Пропуски'] > 0] if missing_df['Пропуски'].sum() > 0 else 'Пропусков нет!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Удаление ненужных колонок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Смотрим названия колонок\n",
    "print('Все колонки:')\n",
    "for i, col in enumerate(df.columns):\n",
    "    print(f'{i+1}. {col}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Удаляем:\n# - CLIENTNUM — ID клиента, не несёт информации для модели\n# - Naive_Bayes_* — служебные колонки Kaggle\n\ncols_to_drop = ['CLIENTNUM']\n\n# Находим служебные колонки Naive_Bayes\nnaive_bayes_cols = [col for col in df.columns if 'Naive_Bayes' in col]\ncols_to_drop.extend(naive_bayes_cols)\n\nprint('Удаляем колонки:')\nfor col in cols_to_drop:\n    print(f'  - {col}')\n\ndf = df.drop(columns=cols_to_drop, errors='ignore')\nprint(f'\\nОсталось колонок: {len(df.columns)}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Анализ целевой переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Распределение целевой переменной Attrition_Flag:')\n",
    "print(df['Attrition_Flag'].value_counts())\n",
    "print('\\nВ процентах:')\n",
    "print((df['Attrition_Flag'].value_counts(normalize=True) * 100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "ax = df['Attrition_Flag'].value_counts().plot(kind='bar', color=['#2ecc71', '#e74c3c'], edgecolor='black')\n",
    "plt.title('Баланс классов (Attrition_Flag)', fontsize=14)\n",
    "plt.xlabel('Статус клиента')\n",
    "plt.ylabel('Количество')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Добавляем подписи\n",
    "for i, v in enumerate(df['Attrition_Flag'].value_counts()):\n",
    "    ax.text(i, v + 100, str(v), ha='center', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\n⚠️ Вывод: Дисбаланс классов ~16% vs 84%')\n",
    "print('Решение: будем использовать class_weight=\"balanced\" в моделях')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Анализ числовых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделяем числовые признаки\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f'Числовых признаков: {len(numeric_cols)}')\n",
    "print(numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Боксплоты для ключевых числовых признаков\n",
    "key_numeric = ['Customer_Age', 'Credit_Limit', 'Total_Trans_Amt', 'Total_Trans_Ct', \n",
    "               'Total_Revolving_Bal', 'Avg_Utilization_Ratio']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(key_numeric):\n",
    "    df.boxplot(column=col, ax=axes[i])\n",
    "    axes[i].set_title(col, fontsize=12)\n",
    "\n",
    "plt.suptitle('Боксплоты числовых признаков', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Распределения по классам\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(key_numeric):\n",
    "    for label in df['Attrition_Flag'].unique():\n",
    "        subset = df[df['Attrition_Flag'] == label][col]\n",
    "        axes[i].hist(subset, alpha=0.5, label=label, bins=30)\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.suptitle('Распределения признаков по классам', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Анализ категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделяем категориальные признаки\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "cat_cols.remove('Attrition_Flag')  # Убираем целевую\n",
    "\n",
    "print(f'Категориальных признаков: {len(cat_cols)}')\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Уникальные значения категориальных признаков\n",
    "for col in cat_cols:\n",
    "    print(f'\\n{col}:')\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация категориальных признаков\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(cat_cols):\n",
    "    df[col].value_counts().plot(kind='bar', ax=axes[i], edgecolor='black')\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Убираем лишний subplot если есть\n",
    "if len(cat_cols) < 6:\n",
    "    axes[-1].axis('off')\n",
    "\n",
    "plt.suptitle('Распределения категориальных признаков', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Корреляционная матрица"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Корреляция числовых признаков\n",
    "plt.figure(figsize=(14, 12))\n",
    "corr = df.select_dtypes(include=[np.number]).corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "sns.heatmap(corr, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=0.5)\n",
    "plt.title('Корреляционная матрица числовых признаков', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сильные корреляции (> 0.5)\n",
    "print('Сильные корреляции (|r| > 0.5):')\n",
    "for i in range(len(corr.columns)):\n",
    "    for j in range(i+1, len(corr.columns)):\n",
    "        if abs(corr.iloc[i, j]) > 0.5:\n",
    "            print(f'  {corr.columns[i]} <-> {corr.columns[j]}: {corr.iloc[i, j]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Итоговая таблица выводов по EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_summary = pd.DataFrame({\n",
    "    'Категория': ['ID', 'Служебные', 'Целевая', 'Категориальные', 'Числовые', 'Дисбаланс'],\n",
    "    'Признак': ['CLIENTNUM', 'Naive_Bayes_*', 'Attrition_Flag', 'Gender, Education и др.', 'Customer_Age и др.', 'Attrition_Flag'],\n",
    "    'Действие': ['Удалить', 'Удалить', 'Бинаризовать', 'LabelEncoder', 'StandardScaler', 'class_weight=balanced'],\n",
    "    'Причина': ['Не несёт информации', 'Служебные колонки Kaggle', '0/1 для модели', 'Преобразование для ML', 'Для LogReg', '16% vs 84%']\n",
    "})\n",
    "\n",
    "print('=' * 80)\n",
    "print('ИТОГИ EDA')\n",
    "print('=' * 80)\n",
    "print(eda_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocessing (Предобработка данных)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Копируем датафрейм для обработки\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Кодируем целевую переменную\n",
    "df_processed['Attrition_Flag'] = df_processed['Attrition_Flag'].map({\n",
    "    'Existing Customer': 0,\n",
    "    'Attrited Customer': 1\n",
    "})\n",
    "\n",
    "print('Целевая переменная закодирована:')\n",
    "print(df_processed['Attrition_Flag'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Кодируем категориальные признаки (отдельный encoder для каждой колонки)\nencoders = {}\n\nprint('Кодирование категориальных признаков:')\nfor col in cat_cols:\n    encoders[col] = LabelEncoder()\n    df_processed[col] = encoders[col].fit_transform(df_processed[col].astype(str))\n    print(f'  {col}: {len(df[col].unique())} уникальных значений')\n\nprint('\\nГотово!')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем результат\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем на X и y\n",
    "X = df_processed.drop('Attrition_Flag', axis=1)\n",
    "y = df_processed['Attrition_Flag']\n",
    "\n",
    "print(f'X shape: {X.shape}')\n",
    "print(f'y shape: {y.shape}')\n",
    "print(f'\\nПризнаки: {list(X.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split (stratified из-за дисбаланса классов)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    stratify=y, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f'Train set: {X_train.shape[0]} samples')\n",
    "print(f'Test set: {X_test.shape[0]} samples')\n",
    "print(f'\\nБаланс в train: {y_train.value_counts(normalize=True).round(3).to_dict()}')\n",
    "print(f'Баланс в test: {y_test.value_counts(normalize=True).round(3).to_dict()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Масштабируем признаки для Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print('Масштабирование выполнено (StandardScaler)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Выбор метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_explanation = pd.DataFrame({\n",
    "    'Метрика': ['Accuracy', 'Precision', 'Recall', 'F1-score'],\n",
    "    'Формула': ['(TP+TN)/(TP+TN+FP+FN)', 'TP/(TP+FP)', 'TP/(TP+FN)', '2*P*R/(P+R)'],\n",
    "    'Когда использовать': [\n",
    "        'Сбалансированные классы',\n",
    "        'Важно не тратить ресурсы зря (False Positive дорого)',\n",
    "        'Важно найти ВСЕХ положительных (False Negative дорого)',\n",
    "        'Компромисс между Precision и Recall'\n",
    "    ],\n",
    "    'Наш случай': ['❌ Дисбаланс', '❌', '✅ ВЫБИРАЕМ', '❌']\n",
    "})\n",
    "\n",
    "print('=' * 80)\n",
    "print('ВЫБОР МЕТРИКИ')\n",
    "print('=' * 80)\n",
    "print(metrics_explanation.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обоснование выбора Recall\n",
    "\n",
    "**Бизнес-контекст**: Предсказание оттока клиентов банка.\n",
    "\n",
    "**Почему Recall?**\n",
    "- **False Negative (FN)** = клиент уйдёт, но модель этого не предскажет → **потеря клиента и прибыли**\n",
    "- **False Positive (FP)** = клиент не уйдёт, но модель предскажет уход → **лишнее удержание**, но клиент останется\n",
    "\n",
    "**Вывод**: Пропустить уходящего клиента (FN) дороже, чем потратить ресурсы на удержание лояльного (FP).\n",
    "\n",
    "**Метрика: Recall** — хотим найти максимум клиентов, которые уйдут."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Модель 1: Логистическая регрессия (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем Logistic Regression\n",
    "lr = LogisticRegression(\n",
    "    class_weight='balanced',  # Учитываем дисбаланс\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "\n",
    "print('=' * 50)\n",
    "print('LOGISTIC REGRESSION')\n",
    "print('=' * 50)\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred_lr, target_names=['Existing', 'Attrited']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Existing', 'Attrited'],\n",
    "            yticklabels=['Existing', 'Attrited'])\n",
    "plt.title('Confusion Matrix: Logistic Regression')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Модель 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем Random Forest (не требует масштабирования)\n",
    "rf = RandomForestClassifier(\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print('=' * 50)\n",
    "print('RANDOM FOREST (default params)')\n",
    "print('=' * 50)\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred_rf, target_names=['Existing', 'Attrited']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens', \n",
    "            xticklabels=['Existing', 'Attrited'],\n",
    "            yticklabels=['Existing', 'Attrited'])\n",
    "plt.title('Confusion Matrix: Random Forest')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Подбор гиперпараметров (GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Сетка параметров для Random Forest\nparam_grid = {\n    'n_estimators': [50, 100, 200],\n    'max_depth': [5, 10, 15, None],\n    'min_samples_split': [2, 5, 10]\n}\n\nprint('Параметры для поиска:')\nfor param, values in param_grid.items():\n    print(f'  {param}: {values}')\n\ntotal_combinations = 1\nfor values in param_grid.values():\n    total_combinations *= len(values)\nprint(f'\\nВсего комбинаций: {total_combinations}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cross-validation strategy\ncv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n\n# GridSearchCV\ngrid_search = GridSearchCV(\n    RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1),\n    param_grid,\n    cv=cv,\n    scoring='recall',  # Оптимизируем по Recall\n    n_jobs=-1,\n    verbose=1\n)\n\nprint('Запускаем GridSearchCV...')\ngrid_search.fit(X_train, y_train)\nprint('\\nГотово!')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 50)\n",
    "print('РЕЗУЛЬТАТЫ GRIDSEARCHCV')\n",
    "print('=' * 50)\n",
    "print(f'\\nЛучшие параметры: {grid_search.best_params_}')\n",
    "print(f'Лучший Recall на CV: {grid_search.best_score_:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Финальная оценка лучшей модели\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred_best = best_rf.predict(X_test)\n",
    "\n",
    "print('=' * 50)\n",
    "print('RANDOM FOREST (tuned)')\n",
    "print('=' * 50)\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred_best, target_names=['Existing', 'Attrited']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix для лучшей модели\n",
    "plt.figure(figsize=(6, 5))\n",
    "cm_best = confusion_matrix(y_test, y_pred_best)\n",
    "sns.heatmap(cm_best, annot=True, fmt='d', cmap='Oranges', \n",
    "            xticklabels=['Existing', 'Attrited'],\n",
    "            yticklabels=['Existing', 'Attrited'])\n",
    "plt.title('Confusion Matrix: Random Forest (tuned)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Сравнение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем метрики всех моделей\n",
    "def get_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'F1': f1_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "results = pd.DataFrame([\n",
    "    {'Модель': 'Logistic Regression', **get_metrics(y_test, y_pred_lr)},\n",
    "    {'Модель': 'Random Forest', **get_metrics(y_test, y_pred_rf)},\n",
    "    {'Модель': 'Random Forest (tuned)', **get_metrics(y_test, y_pred_best)}\n",
    "])\n",
    "\n",
    "# Форматируем для красивого вывода\n",
    "results_display = results.copy()\n",
    "for col in ['Accuracy', 'Recall', 'Precision', 'F1']:\n",
    "    results_display[col] = results_display[col].apply(lambda x: f'{x:.4f}')\n",
    "\n",
    "print('=' * 80)\n",
    "print('СРАВНЕНИЕ МОДЕЛЕЙ')\n",
    "print('=' * 80)\n",
    "print(results_display.to_string(index=False))\n",
    "print('\\n* Основная метрика: Recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация сравнения\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "metrics = ['Accuracy', 'Recall', 'Precision', 'F1']\n",
    "colors = ['#3498db', '#2ecc71', '#e74c3c']\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax = axes[i]\n",
    "    bars = ax.bar(results['Модель'], results[metric], color=colors, edgecolor='black')\n",
    "    ax.set_title(metric, fontsize=12)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Подписи значений\n",
    "    for bar, val in zip(bars, results[metric]):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "                f'{val:.3f}', ha='center', fontsize=10)\n",
    "\n",
    "plt.suptitle('Сравнение метрик моделей', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Важность признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances из лучшей модели Random Forest\n",
    "importances = best_rf.feature_importances_\n",
    "\n",
    "feat_imp = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print('Top 10 важных признаков:')\n",
    "print(feat_imp.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация важности признаков\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_n = 15\n",
    "top_features = feat_imp.head(top_n)\n",
    "\n",
    "plt.barh(range(top_n), top_features['importance'], color='steelblue', edgecolor='black')\n",
    "plt.yticks(range(top_n), top_features['feature'])\n",
    "plt.xlabel('Важность')\n",
    "plt.title(f'Top {top_n} важных признаков (Random Forest)', fontsize=14)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# Добавляем значения\n",
    "for i, v in enumerate(top_features['importance']):\n",
    "    plt.text(v + 0.005, i, f'{v:.3f}', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 80)\n",
    "print('ИТОГОВЫЕ ВЫВОДЫ')\n",
    "print('=' * 80)\n",
    "\n",
    "print('''\n",
    "1. EDA ПОКАЗАЛ:\n",
    "   - Датасет: 10,127 клиентов, 18 признаков (после удаления служебных)\n",
    "   - Дисбаланс классов: ~16% ушедших vs ~84% оставшихся\n",
    "   - Сильные корреляции между транзакционными признаками\n",
    "   - Пропусков нет\n",
    "\n",
    "2. ВЫБРАНА МЕТРИКА RECALL:\n",
    "   - Важнее найти всех потенциально уходящих клиентов\n",
    "   - Пропустить уходящего клиента (FN) дороже, чем лишнее удержание (FP)\n",
    "\n",
    "3. СРАВНИЛИ 2 МОДЕЛИ:\n",
    "   - Logistic Regression (baseline)\n",
    "   - Random Forest (с подбором гиперпараметров через GridSearchCV)\n",
    "''')\n",
    "\n",
    "# Лучшая модель\n",
    "best_model_idx = results['Recall'].idxmax()\n",
    "best_model_name = results.loc[best_model_idx, 'Модель']\n",
    "best_recall = results.loc[best_model_idx, 'Recall']\n",
    "best_f1 = results.loc[best_model_idx, 'F1']\n",
    "best_accuracy = results.loc[best_model_idx, 'Accuracy']\n",
    "\n",
    "print(f'''4. ЛУЧШАЯ МОДЕЛЬ: {best_model_name}\n",
    "   - Параметры: {grid_search.best_params_}\n",
    "   - Recall: {best_recall:.4f}\n",
    "   - F1-score: {best_f1:.4f}\n",
    "   - Accuracy: {best_accuracy:.4f}\n",
    "\n",
    "5. КЛЮЧЕВЫЕ ПРИЗНАКИ (по важности):\n",
    "   - {feat_imp.iloc[0]['feature']}: {feat_imp.iloc[0]['importance']:.3f}\n",
    "   - {feat_imp.iloc[1]['feature']}: {feat_imp.iloc[1]['importance']:.3f}\n",
    "   - {feat_imp.iloc[2]['feature']}: {feat_imp.iloc[2]['importance']:.3f}\n",
    "\n",
    "6. РЕКОМЕНДАЦИИ:\n",
    "   - Обратить внимание на клиентов с низким Total_Trans_Ct (кол-во транзакций)\n",
    "   - Мониторить Total_Revolving_Bal и Total_Trans_Amt\n",
    "   - Модель готова к использованию для раннего выявления оттока\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Ссылка на датасет**: https://www.kaggle.com/datasets/whenamancodes/credit-card-customers-prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}